{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code snip that makes path work so package imports and relative imports work\n",
    "# both in jupyter and as a script\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def in_notebook() -> bool:\n",
    "    try:\n",
    "        from IPython import get_ipython  # noqa: F401\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def here_dir() -> Path:\n",
    "    # When executed as a script, __file__ exists\n",
    "    if '__file__' in globals():\n",
    "        return Path(__file__).resolve().parent\n",
    "    # In a notebook, fall back to the current working directory\n",
    "    return Path.cwd().resolve()\n",
    "\n",
    "def find_project_root(start: Path, markers=('pyproject.toml', 'setup.cfg', '.git', 'paperpi')):\n",
    "    cur = start\n",
    "    for _ in range(20):  # safety bound\n",
    "        # if any marker file or directory exists here, treat this as root\n",
    "        if any((cur / m).exists() for m in markers):\n",
    "            return cur\n",
    "        if cur.parent == cur:\n",
    "            break\n",
    "        cur = cur.parent\n",
    "    return None\n",
    "\n",
    "# 1) Determine where we are\n",
    "_nb_or_script_dir = here_dir()\n",
    "\n",
    "# 2) Locate the project root by walking upward until we find a marker\n",
    "_project_root = find_project_root(_nb_or_script_dir)\n",
    "\n",
    "# 3) Add paths in the right order\n",
    "#    - Ensure local directory is first so 'import constants' resolves locally\n",
    "#    - Ensure project root is also present so package imports work\n",
    "paths_to_add = []\n",
    "if str(_nb_or_script_dir) not in sys.path:\n",
    "    paths_to_add.append(str(_nb_or_script_dir))\n",
    "if _project_root and str(_project_root) not in sys.path:\n",
    "    paths_to_add.append(str(_project_root))\n",
    "\n",
    "# Prepend to sys.path, preserving existing entries\n",
    "sys.path[:0] = paths_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your function must import layout and constants\n",
    "# this is structured to work both in Jupyter notebook and from the command line\n",
    "try:\n",
    "    from . import layout\n",
    "    from . import constants\n",
    "except ImportError:\n",
    "    import layout\n",
    "    import constants\n",
    "import logging\n",
    "from random import randint\n",
    "from paperpi.library.base_plugin import BasePlugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests import exceptions as RequestException\n",
    "from PIL import Image as PILImage\n",
    "from PIL import ImageFile as PILImageFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comic_json(url):\n",
    "    try:\n",
    "        result = requests.get(url)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f'failed to fetch document at {url}: {e}')\n",
    "        result = None\n",
    "\n",
    "    try: \n",
    "        json = result.json()\n",
    "    except (AttributeError, ValueError) as e:\n",
    "        logger.error(f'failed to decode JSON result possibly due to previous errors: {e}')\n",
    "        json = {}\n",
    "    return json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img, target):\n",
    "    '''resize an image to match target dimensions scaling to the longest side\n",
    "    \n",
    "    Args:\n",
    "        img(PIL Image): pillow image object\n",
    "        target(tuple of int): target size in pixles'''\n",
    "    logger.debug('resize image to ')\n",
    "    \n",
    "    idx = img.size.index(max(img.size))\n",
    "    if img.size[idx] < target[idx]:\n",
    "        r = target[idx]/img.size[idx]\n",
    "        new_dim = [int(s * r) for s in img.size]\n",
    "        new_img = img.resize(new_dim, PILImage.LANCZOS)\n",
    "    else: \n",
    "        img.thumbnail(target)\n",
    "        new_img = img\n",
    "        \n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probe_remote_image_size(url: str, session: requests.Session | None = None, max_bytes: int = 65536) -> tuple[int, int] | None:\n",
    "    \"\"\"\n",
    "    Try to discover remote image dimensions by fetching only an initial byte range.\n",
    "    Returns (width, height) if determinable, else None.\n",
    "    Does not write to disk and does not cache.\n",
    "    \"\"\"\n",
    "    s = session or requests.Session()\n",
    "    headers = {'Range': f'bytes=0-{max_bytes-1}'}\n",
    "    try:\n",
    "        resp = s.get(url, headers=headers, stream=True, timeout=15)\n",
    "        resp.raise_for_status()\n",
    "    except RequestException as e:\n",
    "        logger.error(f'failed to probe image size: {e}')\n",
    "        return None\n",
    "    parser = PILImageFile.Parser()\n",
    "    try:\n",
    "        for chunk in resp.iter_content(chunk_size=8192):\n",
    "            if not chunk:\n",
    "                continue\n",
    "            try:\n",
    "                parser.feed(chunk)\n",
    "            except Exception:\n",
    "                # keep feeding; some formats need more data\n",
    "                pass\n",
    "            try:\n",
    "                im = parser.image\n",
    "            except Exception:\n",
    "                im = None\n",
    "            if im is not None and im.size is not None:\n",
    "                return im.size\n",
    "    except RequestException as e:\n",
    "        logger.error(f'error while probing image: {e}')\n",
    "        return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plugin(BasePlugin):\n",
    "    \"\"\"\n",
    "    Fetch random XKCD comics with dimensions <= those specified\n",
    "\n",
    "    Expects BasePlugin to provide:\n",
    "      - self.name\n",
    "      - self.screen_mode, self.layout (optional usage)\n",
    "      - any config/params via self.config / self.params \n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def update_data(self, *, now: str | None = None, **kwargs) -> dict:\n",
    "        \"\"\"\n",
    "        Provide random comic from XKCD\n",
    "\n",
    "        Returns:\n",
    "            dict like {'data': {...}, 'success': True, 'high_priority': False}        \n",
    "        \"\"\"\n",
    "\n",
    "        data = {}\n",
    "        success = False\n",
    "        latest_url = str.join('/', [constants.xkcd_url, constants.xkcd_json_doc])\n",
    "        latest_json = get_comic_json(latest_url)\n",
    "        comic_json = {}\n",
    "        max_x = self.config.get('max_x', 800)\n",
    "        max_y = self.config.get('max_y', 600)\n",
    "        max_retries = self.config.get('max_retries', 10)\n",
    "        resize = self.config.get('resize', False)\n",
    "    \n",
    "        for i in range(max_retries):\n",
    "            logger.info(f\"Randomly selecting comic from {max_retries} total comics.\")\n",
    "            logger.debug(f'Attempt {i} of {max_retries}')\n",
    "            latest_index = latest_json.get('num', False)\n",
    "            if latest_index:\n",
    "                random_index = randint(1, int(latest_index))\n",
    "            else:\n",
    "                random_index = constants.default_comic\n",
    "                logger.error(f\"Using default comic due to previous errors: {random_index}\")\n",
    "                continue\n",
    "            \n",
    "            random_url = str.join('/', [constants.xkcd_url, str(random_index), constants.xkcd_json_doc])\n",
    "            comic_json = get_comic_json(random_url)\n",
    "            \n",
    "            img_url = comic_json.get('img', None)\n",
    "            if not img_url:\n",
    "                logger.error(\"No image URL in comic JSON\")\n",
    "                continue\n",
    "\n",
    "            # Probe dimensions of remote image prior to downloading entire document\n",
    "            size = probe_remote_image_size(img_url)\n",
    "            logger.info(f'size of {img_url}: {size}')\n",
    "            if size is None:\n",
    "                logger.info(\"Could not determine size from remote; skipping\")\n",
    "                continue\n",
    "\n",
    "            w, h = size\n",
    "            if w > max_x or h > max_y:\n",
    "                logger.info(f'Skipping {img_url} due to size {w}x{h} exceeding {max_x}x{max_y}')\n",
    "                continue\n",
    "\n",
    "            # within bounds use downloader to cache\n",
    "            image_file = self.download_image(img_url)\n",
    "            if not image_file:\n",
    "                logger.error(\"Download failed!\")\n",
    "                continue\n",
    "            try:\n",
    "                with PILImage.open(image_file) as image:\n",
    "                    logger.debug(f'Downloaded image size: {image.size}')\n",
    "                comic_json['image_file'] = image_file\n",
    "                data = comic_json\n",
    "                if resize:\n",
    "                    logger.info(f'Upscaling small image to fit {max_x}x{max_y}')\n",
    "                    resized_img = resize\n",
    "                    resized_img.save(image_file)\n",
    "                success = True\n",
    "                break\n",
    "            except Exception as e:\n",
    "                logger.error(f'Failed to process downloaded file: {e}')\n",
    "                continue\n",
    "                    \n",
    "        return {'data': data, 'success': success, 'high_priority': False}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PaperPi-Web-venv-33529be2c6)",
   "language": "python",
   "name": "paperpi-web-venv-33529be2c6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
